# è³‡æ–™å‰è™•ç†æµç¨‹ç¸½æ§è…³æœ¬
# åŸ·è¡Œæ•´å€‹å‰è™•ç†æµç¨‹ï¼š
# 1. åˆä½µå¤šå€‹åŸå§‹ CSV æª”æ¡ˆ
# 2. è³‡æ–™æ¸…ç†
# 3. æ•¸å€¼æ¨™æº–åŒ–
# 4. ç‰¹å¾µé¸æ“‡ï¼ˆä¸¦è¼¸å‡ºé¸å®šç‰¹å¾µæ¸…å–® JSONï¼‰
# 5. ä½¿ç”¨é¸å®šç‰¹å¾µåˆ‡åˆ†è³‡æ–™é›†ï¼ˆè¨“ç·´/é©—è­‰/æ¸¬è©¦ï¼‰
#
# å¯ç›´æ¥åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„åŸ·è¡Œï¼š
# python run_preprocessing_pipeline.py

import os
import shutil
import json
import time
from datetime import datetime
import pandas as pd
from preprocess.merge_csvs import merge_csvs
from preprocess.clean_data import clean_data
from preprocess.scale_features import scale_features
from preprocess.feature_selection import run_feature_selection
from preprocess.data_split import split_data_and_save

if __name__ == "__main__":
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))

    # è¨­å®šè™•ç†èˆ‡å‚™ä»½åƒæ•¸
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    processed_dir = os.path.join(BASE_DIR, "data/processed")
    raw_dir = os.path.join(BASE_DIR, "data/raw")
    version_dir = os.path.join(
        BASE_DIR, "data/versions", f"{timestamp}_preproc")
    corr_threshold = 0.05
    high_corr_threshold = 0.9

    # åœ–è¡¨å„²å­˜ä½ç½®
    figures_dir = os.path.join(processed_dir, "figures")
    os.makedirs(figures_dir, exist_ok=True)
    barplot_path = os.path.join(figures_dir, "correlation_bar_filtered.png")
    heatmap_path = os.path.join(figures_dir, "correlation_heatmap_final.png")

    # æª”æ¡ˆè·¯å¾‘
    merged_csv = os.path.join(processed_dir, "merged.csv")
    cleaned_csv = os.path.join(processed_dir, "cleaned.csv")
    preprocessed_csv = os.path.join(processed_dir, "preprocessed.csv")
    selected_feature_json = os.path.join(
        processed_dir, "selected_features.json")

    # ç´€éŒ„é è™•ç†æ‰€è€—è²»æ™‚é–“
    start_time = time.time()

    # 1. åˆä½µå¤šå€‹ raw CSV æˆ merged.csv
    print("Step 1: åˆä½µ CSV æª”æ¡ˆ...")
    merge_csvs(raw_dir, merged_csv)
    merged_rows = len(pd.read_csv(merged_csv))

    # 2. æ¸…ç†è³‡æ–™
    print("Step 2: æ¸…ç†è³‡æ–™...")
    clean_data(merged_csv, cleaned_csv)

    # 3. æ•¸å€¼æ¨™æº–åŒ–
    print("Step 3: æ•¸å€¼æ¨™æº–åŒ–...")
    scale_features(cleaned_csv, preprocessed_csv)

    # 4. ç‰¹å¾µé¸æ“‡
    print("Step 4: ç‰¹å¾µé¸æ“‡...")
    selected_features, corr_matrix = run_feature_selection(
        input_csv_path=preprocessed_csv,
        feature_output_path=selected_feature_json,
        corr_threshold=corr_threshold,
        high_corr_threshold=high_corr_threshold,
        barplot_output_path=barplot_path,
        heatmap_output_path=heatmap_path
    )

    # 5. åˆ‡åˆ†è³‡æ–™é›†ï¼ˆtrain/val/testï¼‰
    print("Step 5: åˆ‡åˆ†è³‡æ–™é›†...")
    split_data_and_save(preprocessed_csv, selected_feature_json, processed_dir)

    # è¨ˆæ™‚çµæŸ
    end_time = time.time()
    elapsed_seconds = round(end_time - start_time, 2)

    # 6 å‚™ä»½åˆ°ç‰ˆæœ¬è³‡æ–™å¤¾ï¼ˆå« figuresï¼‰
    print(f"ğŸ—‚ï¸ å‚™ä»½è™•ç†å¾Œè³‡æ–™åˆ° {version_dir}")
    shutil.copytree(processed_dir, version_dir)

    # 7 å¯«å…¥ version.json
    version_info = {
        "timestamp": timestamp,
        "merged_rows": merged_rows,
        "selected_features": selected_features,
        "corr_threshold": corr_threshold,
        "high_corr_threshold": high_corr_threshold,
        "elapsed_time_seconds": elapsed_seconds,
        "figures": {
            "barplot": "figures/correlation_bar_filtered.png",
            "heatmap": "figures/correlation_heatmap_final.png"
        }
    }
    with open(os.path.join(version_dir, "version.json"), "w") as f:
        json.dump(version_info, f, indent=2)

    print(f"âœ… å‰è™•ç†æµç¨‹å®Œæˆï¼å…±è€—æ™‚ {elapsed_seconds} ç§’ï¼Œversion.json å·²å»ºç«‹")
